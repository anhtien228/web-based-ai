{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Fine-tuneing BART model**\n\nThe notebook consists the fine tuning process BART model from Hugging Face (created by ssleifer), which already had a good performance on summarizing the text documents. Since there are also many datasets out there, I want to try fine tuning the model to see whether its performance is improved, and how the tuning process will affect it regarding different use-cases.\n\nThe dataset used in this notebook is **wiki_lingua** from GEM Benchmark, which contains large-scale dataset for cross-ligual summarization (in 18 languages). The data was extract from the documents on WikiHow site.\n\nAt the beginning, I aim to use the **distilbart-xsum-12-6** model and **english** portion of wiki_lingua dataset for examining purposes. In future work, I'd also want to try out the BARTpho model (created by VinAI) that is specifically used for Vietnamese text summarization, and  the **vietnamese** portion from the wiki_lingua dataset.","metadata":{"id":"FTT8rRBbZxgL"}},{"cell_type":"markdown","source":"#### **Setup**\n\nThe notebook was intended to be ran locally, but due to the lack of GPU and memory, I had switched the implementation to Google Colab. Nevertheless, Google Colab cannot stay active for too long unless I pay for Pro subscription, so I decided to use Kaggle as it can process the notebook in the background and will never timeout (before reaching the quota)","metadata":{"id":"pVInuJCVZxgM"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"xvx0Aj12Z5Kn","outputId":"33aa2b73-b6eb-47ab-aa68-4b824c5423d4","execution":{"iopub.status.busy":"2022-07-04T09:12:42.467228Z","iopub.execute_input":"2022-07-04T09:12:42.467734Z","iopub.status.idle":"2022-07-04T09:12:42.495116Z","shell.execute_reply.started":"2022-07-04T09:12:42.467657Z","shell.execute_reply":"2022-07-04T09:12:42.493459Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install datasets\n!pip install transformers\n!pip install rouge_score\n!pip install sentencepiece","metadata":{"id":"023E26jhaV7i","outputId":"a4ad45c1-4980-4fc7-f60b-7b99928944d0","execution":{"iopub.status.busy":"2022-07-04T09:12:42.497592Z","iopub.execute_input":"2022-07-04T09:12:42.498225Z","iopub.status.idle":"2022-07-04T09:13:30.712761Z","shell.execute_reply.started":"2022-07-04T09:12:42.498184Z","shell.execute_reply":"2022-07-04T09:13:30.711329Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport datasets\nfrom transformers import (\n    BartForConditionalGeneration,\n    AutoTokenizer,\n    Seq2SeqTrainingArguments, \n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq\n)\nimport nltk\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"id":"pkiW-m_UZxgM","execution":{"iopub.status.busy":"2022-07-04T11:30:10.610610Z","iopub.execute_input":"2022-07-04T11:30:10.611024Z","iopub.status.idle":"2022-07-04T11:30:10.617775Z","shell.execute_reply.started":"2022-07-04T11:30:10.610995Z","shell.execute_reply":"2022-07-04T11:30:10.616399Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"#### **Model and Tokenizer**","metadata":{"id":"7pGniyhpZxgN"}},{"cell_type":"code","source":"model_name = \"sshleifer/distilbart-xsum-12-6\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name)\n\nencoder_max_len = 256\ndecoder_max_len = 64","metadata":{"id":"sTAFyomNZxgO","outputId":"f73aa1b8-56ec-4ffc-a533-006d9bb4abcd","execution":{"iopub.status.busy":"2022-07-04T11:30:14.478383Z","iopub.execute_input":"2022-07-04T11:30:14.478778Z","iopub.status.idle":"2022-07-04T11:30:24.336419Z","shell.execute_reply.started":"2022-07-04T11:30:14.478748Z","shell.execute_reply":"2022-07-04T11:30:24.335317Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Check the vocabulary size of tokenizer and model whether they are matching\nmismatch = False\n\nprint(f\"Tokenizer: {tokenizer.vocab_size}\")\nprint(f\"Model: {model.config.vocab_size}\")\n\nif len(tokenizer) != model.config.vocab_size:\n    mismatch = True","metadata":{"id":"Qv6JlFlzZxgO","outputId":"2e095cf0-8d9b-4f4b-a046-02b17bd5ac44","execution":{"iopub.status.busy":"2022-07-04T11:30:28.294669Z","iopub.execute_input":"2022-07-04T11:30:28.295102Z","iopub.status.idle":"2022-07-04T11:30:28.303523Z","shell.execute_reply.started":"2022-07-04T11:30:28.295071Z","shell.execute_reply":"2022-07-04T11:30:28.301670Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"if (mismatch):\n    model.resize_token_embeddings(len(tokenizer))\n    print(f\"Tokenizer: {tokenizer.vocab_size}\")\n    print(f\"Model: {model.config.vocab_size}\")","metadata":{"id":"CwPQhBk5ZxgP","outputId":"368c6438-eb0d-4448-baa9-94c06c68db1c","execution":{"iopub.status.busy":"2022-07-04T11:30:30.227210Z","iopub.execute_input":"2022-07-04T11:30:30.227645Z","iopub.status.idle":"2022-07-04T11:30:31.161736Z","shell.execute_reply.started":"2022-07-04T11:30:30.227614Z","shell.execute_reply":"2022-07-04T11:30:31.160390Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"#### **Data preparation**\n**Read data**","metadata":{"id":"bBjhLIFDZxgP"}},{"cell_type":"code","source":"# # Use local dataset\n# src = \"drive/MyDrive/Personal Workspace/Colab Notebooks/NLP/data_sm.jsonl\"\n# data = datasets.load_dataset(\"json\", data_files=src)\n\n# train_val_test = data[\"train\"].train_test_split(shuffle=True, seed=42, test_size=0.1)\n\n# dataset = datasets.DatasetDict({\n#     \"train\": train_val_test[\"train\"], # Train\n#     \"val\": train_val_test[\"test\"], # Validation\n# })","metadata":{"id":"vwQ7kZJzZxgU","execution":{"iopub.status.busy":"2022-07-04T09:14:36.015344Z","iopub.execute_input":"2022-07-04T09:14:36.015793Z","iopub.status.idle":"2022-07-04T09:14:36.022547Z","shell.execute_reply.started":"2022-07-04T09:14:36.015751Z","shell.execute_reply":"2022-07-04T09:14:36.020900Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Download dataset\nlanguage = \"english\"\n\ndata = datasets.load_dataset(\"wiki_lingua\", name=language, split=\"train[:1000]\")","metadata":{"id":"rKVN8AeIGr7_","outputId":"9de72d14-11cf-490a-e9a2-8eba9e7166e7","execution":{"iopub.status.busy":"2022-07-04T11:30:34.192716Z","iopub.execute_input":"2022-07-04T11:30:34.193113Z","iopub.status.idle":"2022-07-04T11:30:35.294744Z","shell.execute_reply.started":"2022-07-04T11:30:34.193083Z","shell.execute_reply":"2022-07-04T11:30:35.293571Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing and Split**","metadata":{"id":"fYh9M5VgZxgR"}},{"cell_type":"code","source":"def flatten(dataset):\n    return {\n        \"document\": dataset[\"article\"][\"document\"],\n        \"summary\": dataset[\"article\"][\"summary\"],\n    }\n\n\ndef list2samples(dataset):\n    documents = []\n    summaries = []\n    for sample in zip(dataset[\"document\"], dataset[\"summary\"]):\n        if len(sample[0]) > 0:\n            documents += sample[0]\n            summaries += sample[1]\n    return {\"document\": documents, \"summary\": summaries}\n\n\ndataset = data.map(flatten, remove_columns=[\"article\", \"url\"])\ndataset = dataset.map(list2samples, batched=True)\n\ntrain_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.2).values()","metadata":{"id":"A89cj5_JHFpf","outputId":"662c913f-655f-425b-a39d-df270438a3a3","execution":{"iopub.status.busy":"2022-07-04T11:30:39.378576Z","iopub.execute_input":"2022-07-04T11:30:39.379302Z","iopub.status.idle":"2022-07-04T11:30:39.768595Z","shell.execute_reply.started":"2022-07-04T11:30:39.379252Z","shell.execute_reply":"2022-07-04T11:30:39.767322Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"**Tokenize data**","metadata":{"id":"LwpxxnvFZxgV"}},{"cell_type":"code","source":"def batch_tokenizing(batch, tokenizer, max_input_len, max_output_len):\n    input_, output_ = batch[\"document\"], batch[\"summary\"]\n    input_tokenized = tokenizer(\n        input_, padding=\"max_length\", max_length=max_input_len, truncation=True\n    )\n    output_tokenized = tokenizer(\n        output_, padding=\"max_length\", max_length=max_output_len, truncation=True\n    )\n\n    batch = {key: value for key, value in input_tokenized.items()}\n\n    batch[\"labels\"] =[[-100 if token == tokenizer.pad_token_id else token for token in l]\n                        for l in output_tokenized[\"input_ids\"]]\n\n    return batch\n\ntrain_data = train_data_txt.map(\n    lambda batch: batch_tokenizing(\n        batch, tokenizer, encoder_max_len, decoder_max_len\n    ),\n    batched=True,\n    remove_columns=train_data_txt.column_names,\n)\n\nval_data = validation_data_txt.map(\n    lambda batch: batch_tokenizing(\n        batch, tokenizer, encoder_max_len, decoder_max_len\n    ),\n    batched=True,\n    remove_columns=validation_data_txt.column_names,\n)","metadata":{"id":"H8TN4vpAZxgV","outputId":"c1fe2a23-7f19-4f36-f848-7f84c0a71310","scrolled":true,"execution":{"iopub.status.busy":"2022-07-04T11:30:42.592352Z","iopub.execute_input":"2022-07-04T11:30:42.592731Z","iopub.status.idle":"2022-07-04T11:30:46.681169Z","shell.execute_reply.started":"2022-07-04T11:30:42.592701Z","shell.execute_reply":"2022-07-04T11:30:46.679847Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"#### **Training model**","metadata":{"id":"cEDMhulRZxgW"}},{"cell_type":"markdown","source":"**Metrics**","metadata":{"id":"91iSZf_zZxgX"}},{"cell_type":"code","source":"nltk.download(\"punkt\", quiet=True)\n\nmetric = datasets.load_metric(\"rouge\")\n\ndef postprocess_data(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # Join sequences with newline between them for rougle calculation\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    return preds, labels\n\ndef calculate_metric(eval_result):\n    preds, labels = eval_result\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Preprocess prediction and label for metric computation\n    decoded_preds, decoded_labels = postprocess_data(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n\n    pred_len = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"res_\"] = np.mean(pred_len)\n    result = {key: round(val, 4) for key, val in result.items()}\n\n    return result","metadata":{"id":"AHf8xMsWZxgX","outputId":"ec477198-c8a1-4e9f-ca55-0145face407a","execution":{"iopub.status.busy":"2022-07-04T11:30:53.561502Z","iopub.execute_input":"2022-07-04T11:30:53.561899Z","iopub.status.idle":"2022-07-04T11:30:54.330501Z","shell.execute_reply.started":"2022-07-04T11:30:53.561870Z","shell.execute_reply":"2022-07-04T11:30:54.328942Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"**Training arguments**","metadata":{"id":"haxwmuDWZxgX"}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"0ld19TJUZxgY","outputId":"204cbec6-b6a3-4cdd-9924-16180dec2167","execution":{"iopub.status.busy":"2022-07-04T11:12:46.654085Z","iopub.execute_input":"2022-07-04T11:12:46.654570Z","iopub.status.idle":"2022-07-04T11:12:46.772743Z","shell.execute_reply.started":"2022-07-04T11:12:46.654521Z","shell.execute_reply":"2022-07-04T11:12:46.771291Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_args = Seq2SeqTrainingArguments(\n    output_dir=\"distilbart-ftn-wiki_lingua\",\n    num_train_epochs=1,\n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=5,\n    per_device_eval_batch_size=5,\n    warmup_steps=420,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    predict_with_generate=True,\n    logging_dir=\"logs\",\n    logging_steps=50,\n    save_total_limit=3,\n)\n\ndata_colla = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=train_args,\n    data_collator=data_colla,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    tokenizer=tokenizer,\n    compute_metrics=calculate_metric,\n)","metadata":{"id":"U5xgH1HDZxgY","outputId":"67608fce-6cfe-4290-db3e-d3a4831f7044","execution":{"iopub.status.busy":"2022-07-04T11:30:58.090418Z","iopub.execute_input":"2022-07-04T11:30:58.090819Z","iopub.status.idle":"2022-07-04T11:30:58.366594Z","shell.execute_reply.started":"2022-07-04T11:30:58.090790Z","shell.execute_reply":"2022-07-04T11:30:58.365363Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:31:01.422775Z","iopub.execute_input":"2022-07-04T11:31:01.424047Z","iopub.status.idle":"2022-07-04T11:31:01.430292Z","shell.execute_reply.started":"2022-07-04T11:31:01.423980Z","shell.execute_reply":"2022-07-04T11:31:01.428888Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"**Train model (fine-tune)**","metadata":{"id":"yScOYc-IWPcm"}},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"myD1l12JgOgS","execution":{"iopub.status.busy":"2022-07-04T11:31:03.545282Z","iopub.execute_input":"2022-07-04T11:31:03.546542Z","iopub.status.idle":"2022-07-04T11:34:30.673519Z","shell.execute_reply.started":"2022-07-04T11:31:03.546485Z","shell.execute_reply":"2022-07-04T11:34:30.672060Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"#### **Evaluate and comparison**\n\nCompare the summaries from the fine-tuned BART model and the original BART model","metadata":{"id":"LNUn-rcvX8h1"}},{"cell_type":"code","source":"def generate_summary(samples, model):\n    inputs = tokenizer(\n        samples[\"document\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=encoder_max_len,\n        return_tensors=\"pt\",\n    )\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n    return outputs, output_str\n\noriginal_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\nsample_test = validation_data_txt.select(range(15))\n\nsummary_before = generate_summary(sample_test, original_model)[1]\nsummary_after = generate_summary(sample_test, model)[1]","metadata":{"id":"FZDu7_JfYCxO","execution":{"iopub.status.busy":"2022-07-04T11:34:30.676161Z","iopub.execute_input":"2022-07-04T11:34:30.676533Z","iopub.status.idle":"2022-07-04T11:35:30.684348Z","shell.execute_reply.started":"2022-07-04T11:34:30.676504Z","shell.execute_reply":"2022-07-04T11:35:30.683066Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"from tabulate import tabulate","metadata":{"id":"VhvfVjKuZdS8","execution":{"iopub.status.busy":"2022-07-04T11:08:40.107596Z","iopub.execute_input":"2022-07-04T11:08:40.108267Z","iopub.status.idle":"2022-07-04T11:08:40.114088Z","shell.execute_reply.started":"2022-07-04T11:08:40.108220Z","shell.execute_reply":"2022-07-04T11:08:40.112592Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print(tabulate(\n        zip(\n            range(len(summary_after)),\n            summary_after,\n            summary_before,\n        ),\n        headers=[\"ID\", \"Summary before\", \"Summary after\"]\n    )\n)\n\nprint(\"\\nSource document:\\n\")\nprint(tabulate(list(enumerate(sample_test[\"document\"])), headers=[\"ID\", \"Document\"]))\n\nprint(\"\\nTarget summary:\\n\")\nprint(tabulate(list(enumerate(sample_test[\"summary\"])), headers=[\"ID\", \"Target summary\"]))","metadata":{"id":"BSTcmMcFZieu","execution":{"iopub.status.busy":"2022-07-04T11:35:30.686390Z","iopub.execute_input":"2022-07-04T11:35:30.686853Z","iopub.status.idle":"2022-07-04T11:35:30.735675Z","shell.execute_reply.started":"2022-07-04T11:35:30.686813Z","shell.execute_reply":"2022-07-04T11:35:30.734394Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"#### **Share model to HuggingFace Hub**","metadata":{}},{"cell_type":"code","source":"!sudo apt-get install git-lfs\n!git lfs install","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:17:01.884190Z","iopub.execute_input":"2022-07-04T11:17:01.885735Z","iopub.status.idle":"2022-07-04T11:17:09.799014Z","shell.execute_reply.started":"2022-07-04T11:17:01.885697Z","shell.execute_reply":"2022-07-04T11:17:09.797585Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(\"distilbart-ftn-wiki_lingua\", use_temp_dir=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:35:30.738688Z","iopub.execute_input":"2022-07-04T11:35:30.739568Z","iopub.status.idle":"2022-07-04T11:47:34.092752Z","shell.execute_reply.started":"2022-07-04T11:35:30.739523Z","shell.execute_reply":"2022-07-04T11:47:34.088982Z"},"trusted":true},"execution_count":81,"outputs":[]}]}